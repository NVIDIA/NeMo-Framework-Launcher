run:
  name: 'word-length-filter'
  # Output directory to where the extracted documents will be written
  results_dir: ${base_results_dir}/${.name}
  time_limit: "08:00:00"
  dependency: "singleton"
  nodes: 1
  partition:
  cpus_per_node: 48

# Provide the downloader, data loader and extraction modules that
# define how the dataset will be built from the URLs
filter:
  filter_module: ndc.filter.heuristics.filter.LongWordFilter
  params:
    max_word_length: 1000

input_dir: "/datasets/json/original"
output_dir: "/datasets/json/filtered"
