run:
  name: eval_${.task_name}_${.model_train_name}
  time_limit: "04:00:00"
  dependency: "singleton"
  model_train_name: stable_diffusion_860m_res_512
  task_name: "fid_clip"  # Rename this name to be more clear
  results_dir: ${base_results_dir}/${.model_train_name}/${.name}
  node_array_size: 8 # Need to be set to `len(classifier_free_guidance) * nnodes_per_cfg`
  ntasks_per_node: 8 # Number of gpus per node in preprocessing step.

generate_images: True
compute_fid_scores: True
compute_clip_scores: True
plot_fid_clip: True
clip_version: ViT-L-14

fid:
  classifier_free_guidance:
    - 1.5
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
  nnodes_per_cfg: 1
  ntasks_per_node: ${evaluation.run.ntasks_per_node}
  local_task_id: null
  num_images_to_eval: 30000
  coco_captions_path: ${data_dir}/fid_evaluation/coco2014/coco2014_val_sampled_30k/captions
  coco_images_path: ${data_dir}/fid_evaluation/coco2014/coco2014_val/images_256
  save_path: ${evaluation.run.results_dir}/generated_images

infer:
  unconditional_guidance_scale: null
  num_images_per_prompt: 1
  height: 512
  width: 512
  down_factor: 8
  inference_steps: 50
  sampler_type: 'PLMS'
  eta: 0
  output_type: 'pil'
  save_to_file: False # We need to rename and maintain the order of images for clip score calculation, so we will save it outside the inference pipeline
  out_path: null # not used here
  seed: 123
  batch_size: 4
  prompts:

trainer:
  devices: ${evaluation.run.ntasks_per_node}
  num_nodes: 1
  accelerator: gpu
  precision: 16
  logger: False # logger provided by exp_manager

model:
  restore_from_path: ${base_results_dir}/${evaluation.run.model_train_name}/results/checkpoints/nemo_stable_diffusion.nemo  # Path to a trained CLIP .nemo file
  precision: ${evaluation.trainer.precision}